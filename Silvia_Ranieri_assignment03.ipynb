{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Silvia_Ranieri_assignment03.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glx6MMb_E3Nb"
      },
      "source": [
        "# **Advanced Machine Learning - **<br/>\n",
        "**Master's Degree in Data Science (A.Y. 2021/2022)**<br/>\n",
        "**University of Milano - Bicocca**<br/>\n",
        "\n",
        "Assignment 03\n",
        "\n",
        "Silvia Ranieri 878067\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYRUVEowOm1y"
      },
      "source": [
        "La relazione deve contenere:\n",
        "- una descrizione dell'architettura progettata\n",
        "- i parametri contano per ogni strato\n",
        "- gli iperparametri utilizzati per l'addestramento (dimensione batch, tasso di apprendimento, ottimizzatore, numero di epoche, ecc.)\n",
        "- un grafico della perdita/accuratezza della formazione e della convalida\n",
        "- prestazioni di classificazione su formazione, convalida (se utilizzata) e set di test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9ozDG56Otad"
      },
      "source": [
        "#LIBRERIE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-tZOLE8E5FB"
      },
      "source": [
        "import numpy as np \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1DU0FBcOyuC"
      },
      "source": [
        "#Preparazione dei dati\n",
        "\n",
        "**Obiettivo**: La CNN deve essere progettata con l'obiettivo di raggiungere la massima precisione possibile sul set di prova, con il vincolo rigido di un massimo di 6K parametri apprendibili.\n",
        "\n",
        "Set di dati: Set di dati di input: cifre MNIST (dimensioni di input 28x28x1, numero di classi: 10).\n",
        "\n",
        "Questo dataset è composto da un set di addestramento di 60.000 esempi e un set di test di 10.000.\n",
        "\n",
        " Le cifre Mnist vanno da 0 a 9, quindi questo è un problema di classificazione multiclasse con 10 classi e l'immagine di input è (28 x 28).\n",
        "\n",
        "In primo luogo, si normalizza nella scala di grigi per ridurre l'effetto delle differenze di illuminazione al fine di facilitare il training. Dopo si passa a espandere la dimensione dei dati 28x28x1 per gestire l'input della CNN. \n",
        "\n",
        "Vengono convertiti i dati di train e test in una matrice di classe binaria con dieci caratteristiche.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "h6gKZciBE57-",
        "outputId": "b9556c7a-43c2-4288-a863-dacd170ce315"
      },
      "source": [
        "# Model/data parameters \n",
        "num_classes = 10 #digits 0-9\n",
        "input_shape = (28,28,1)\n",
        "\n",
        "# load the data and divide it into train/test split\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train= x_train.astype(\"float32\") / 255\n",
        "x_test, x_test.astype(\"float32\") / 255\n",
        "\n",
        "# plot some samples\n",
        "image_index  = 7777\n",
        "print(y_train[image_index])\n",
        "plt.imshow(x_train[image_index],cmap='gray')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAG40lEQVR4nO3dTYjNfR/H8Tmenzey8LwQNVYKmZKHPA0LUaTEZC02FrKULDwssERRsiJZSLJQBmtssaGsFGKhiJx7dd3dd83/e7pmuOZzXK/Xcj79z5mm3v7l1/+cVrvd7gHyjBntXwAYmjghlDghlDghlDgh1LhqbLVa/isXfrN2u90a6ufunBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBBKnBCq/ApA+F9Tp04t94GBgXLv6+sb9ntv27at3F+9elXu169fL/fLly//7d/pd3PnhFDihFDihFDihFDihFDihFDihFCtdrvdPLZazSNdaebMmeV++vTpxm3r1q3ltfPmzSv3Dx8+lPuTJ08at2/fvpXXbtiwodyfP39e7v39/eX+O7Xb7dZQP3fnhFDihFDihFDihFDihFDihFDihFCe5/zDHDx4sNyPHDlS7osXL27cPn/+XF577dq1cj927Fi5v3v3rtwrmzZtKvfE5zU7ceeEUOKEUOKEUOKEUOKEUOKEUB4Z6zKdHtu6c+dOuY8ZU/97fOrUqcatepysp6en58uXL+XeyYoVKxq3ly9fjui9lyxZUu4vXrwo99/JI2PQZcQJocQJocQJocQJocQJocQJoZxzhpkzZ065dzrvmzRpUrlv37693O/fv1/ulfHjx5f73bt3y33jxo2N26FDh8prL126VO7JnHNClxEnhBInhBInhBInhBInhBInhPLRmGGOHz9e7tOmTSv3W7dulftIzjE7uXDhQrlv2bJl2K/98ePHYV/brdw5IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZTnOUfBrFmzGrenT5+W186fP7/ce3t7y73T57MuWLCgcbtx40Z57apVq8q91RryscX/2rt3b+N28+bN8tqfP3+WezLPc0KXESeEEieEEieEEieEEieEEieE8jznKBg3rvnPPmHChBG99ty5c8u903ORFy9ebNxWrlxZXvvt27dyP3r0aLk/ePCgcevmc8zhcueEUOKEUOKEUOKEUOKEUOKEUI5SRsHUqVMbtylTpozotXfu3Fnut2/fLvcZM2Y0bp8+fSqv3bFjR7k/fvy43Pl/7pwQSpwQSpwQSpwQSpwQSpwQSpwQyjnnKKgeGfv8+XN57fTp08v98OHDw/qd/lKdRe7evbu89t/4NX2/kzsnhBInhBInhBInhBInhBInhBInhHLOOQqWL1/euI0dO3ZEr/3169dyP3HiRLlXH43Z6XlOfi13TgglTgglTgglTgglTgglTgglTgjVarfbzWOr1TzSqK+vr9wfPXrUuI30KwAHBwfLvdPn2nZ6npRfr91ut4b6uTsnhBInhBInhBInhBInhBInhBInhHLOOQz79+8v96tXr5b7+/fvG7crV66U1+7atavce3t7y/3s2bPlfuzYsXLn13POCV1GnBBKnBBKnBBKnBBKnBDKR2MOYfPmzeV+7ty5cq+Op3p6enr27dvXuD18+LC8dtmyZeXe6Shl4sSJ5U4Od04IJU4IJU4IJU4IJU4IJU4IJU4I9ceec06ePLlxW79+fXnt3bt3y/3Hjx/lfuDAgXLvdJZZuXbtWrn39/eX++LFi4f93vyz3DkhlDghlDghlDghlDghlDghlDgh1B97zrlo0aLG7d69e+W1X79+LffVq1eX+7Nnz8q9Mnv27HI/fvx4uf/8+bPcO52TksOdE0KJE0KJE0KJE0KJE0KJE0KJE0J17Tlnp/PAmzdvDvu1BwYGyr3TOeaYMfW/eTt27Gjczp8/X167cOHCcn/69Gm5j+Tvwj/LnRNCiRNCiRNCiRNCiRNCiRNCtaqvq2u1WvV32Y2idevWlfvg4OCwX3v8+PHlPm/evHI/c+ZMue/Zs+dv/05/uXPnTrnv3r273L9//z7s9+b3aLfbraF+7s4JocQJocQJocQJocQJocQJocQJobr2kbE3b96U+9u3bxu3+fPnl9e+fv263GfMmDGi/cOHD43b5cuXy2tPnjxZ7s4x/xzunBBKnBBKnBBKnBBKnBBKnBBKnBCqa5/n7GTp0qWN28WLF8tr16xZM6L37nQGu3bt2satOp/lz+R5Tugy4oRQ4oRQ4oRQ4oRQ4oRQ4oRQf+w5J3QL55zQZcQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocQJocqvAARGjzsnhBInhBInhBInhBInhBInhPoPNk5EGuZCrUgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOmVT1ofE8Tq",
        "outputId": "2d40ce8c-394b-41ed-8107-47221de15d58"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMLbh1HrE-c7",
        "outputId": "4fd2379d-48e2-4656-cd89-e92abf87ce2d"
      },
      "source": [
        "#expand dimension of our data (28,28,1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape: \", x_train.shape)\n",
        "print(\"x_train samples: \", x_train.shape[0])\n",
        "print(\"x_test sample: \", x_test.shape[0])   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape:  (60000, 28, 28, 1)\n",
            "x_train samples:  60000\n",
            "x_test sample:  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-qGzc5kFDK4",
        "outputId": "6ffe3b03-57c1-4821-9e2c-e16c01b3f1e3"
      },
      "source": [
        "#convert class vectors to binary class matrics\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMaEsgueO-gg"
      },
      "source": [
        "Definisco le metriche che mi serviranno per valutare il modello e le sue performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm2HiyV340qb"
      },
      "source": [
        "#definizione delle metriche:\n",
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28soj_2oOedd"
      },
      "source": [
        "#MODELLO\n",
        "\n",
        "Per soddisfare il vincolo e mantenere il numero di parametri sotto 6k, il modello ha 2 livelli di convoluzione con dimensione 8 per ogni livello, mentre la dimensione del filtro è (3x3x1). Dopo un livello di pooling massimo di 2x2. Poi uno strato convoluzione di 16 con dimensione del filtro è (3x3) e livello di polling 2x2. Il totale dei parametri è 5842.\n",
        "Attraverso la regolarizzazione (Dropout) viene eliminato il 30% dei neuroni. \n",
        "\n",
        "**Funzione di attivazione:** scelgo la funzione ReLU che è adatta per questo modello e in generale è una buona scelta per i livelli nascosti.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3vlSj1GFJd-",
        "outputId": "7de0cf4d-e8b4-441d-f505-8a7b67c26f13"
      },
      "source": [
        "model = keras.Sequential (\n",
        "    [\n",
        "      keras.Input(shape =  input_shape),\n",
        "    \n",
        "      layers.Conv2D(8, kernel_size=(3,3), activation='relu'),\n",
        "      layers.Conv2D(8, kernel_size=(3,3), activation='relu'),\n",
        "      layers.MaxPool2D(pool_size=(2,2)),\n",
        "     \n",
        "      layers.Conv2D(16, kernel_size=(3,3), activation='relu'),\n",
        "      layers.MaxPool2D(pool_size=(2,2)),\n",
        "      \n",
        "      layers.Flatten(),\n",
        "      layers.Dropout(0.3),\n",
        "      layers.Dense(num_classes, activation='softmax'),\n",
        "    ]\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 24, 24, 8)         584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 10, 10, 16)        1168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                4010      \n",
            "=================================================================\n",
            "Total params: 5,842\n",
            "Trainable params: 5,842\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnliKPLHPP1I"
      },
      "source": [
        "#Addestramento\n",
        "\n",
        "**Funzione di perdita:** scelgo categorical_crossentropy perché è particolarmente adatto per compiti di classificazione categoriale, ho provato mse, mae e sparse cross_entropy categorico ma con risultati peggiori.\n",
        "\n",
        "**Ottimizzatore:** Ho scelto Adam ho provato a utilizzare un ottimizzatore diverso come SGD ma Adam funziona meglio.\n",
        "\n",
        "**Epoche:** il numero di epoche è 90, ho notato che aumentando il modello non migliora.\n",
        "\n",
        "**Dimensione batch:** Ho provato diversi valori e notato che con 128 si otteneva risultati migliori.\n",
        "\n",
        "**Metriche:** Ho stabilito diverse metriche l’accuratezza, f1_m, precision, recall.\n",
        "\n",
        "Ho impostato i dati di validazione al 20% del training. \n",
        "\n",
        "**Funzione di output: **softmax, prestazioni migliori per questo modello. Inoltre, utile nei problemi di classificazione con n classi (n > 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtabGb9hFMXQ",
        "outputId": "103ad398-b4d4-40de-91f0-c475d2e85e2d"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 90  \n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
        "\n",
        "network_history = model.fit(x_train, y_train, batch_size=batch_size,  epochs = epochs, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.5783 - accuracy: 0.8157 - f1_m: 0.7693 - precision_m: 0.8282 - recall_m: 0.7391 - val_loss: 0.1262 - val_accuracy: 0.9645 - val_f1_m: 0.9643 - val_precision_m: 0.9720 - val_recall_m: 0.9568\n",
            "Epoch 2/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.1543 - accuracy: 0.9530 - f1_m: 0.9533 - precision_m: 0.9614 - recall_m: 0.9454 - val_loss: 0.0850 - val_accuracy: 0.9747 - val_f1_m: 0.9758 - val_precision_m: 0.9801 - val_recall_m: 0.9715\n",
            "Epoch 3/90\n",
            "375/375 [==============================] - 8s 23ms/step - loss: 0.1157 - accuracy: 0.9636 - f1_m: 0.9645 - precision_m: 0.9698 - recall_m: 0.9594 - val_loss: 0.0704 - val_accuracy: 0.9794 - val_f1_m: 0.9796 - val_precision_m: 0.9830 - val_recall_m: 0.9762\n",
            "Epoch 4/90\n",
            "375/375 [==============================] - 10s 26ms/step - loss: 0.0978 - accuracy: 0.9695 - f1_m: 0.9695 - precision_m: 0.9737 - recall_m: 0.9654 - val_loss: 0.0605 - val_accuracy: 0.9822 - val_f1_m: 0.9828 - val_precision_m: 0.9848 - val_recall_m: 0.9808\n",
            "Epoch 5/90\n",
            "375/375 [==============================] - 9s 23ms/step - loss: 0.0875 - accuracy: 0.9727 - f1_m: 0.9730 - precision_m: 0.9763 - recall_m: 0.9698 - val_loss: 0.0534 - val_accuracy: 0.9847 - val_f1_m: 0.9848 - val_precision_m: 0.9868 - val_recall_m: 0.9827\n",
            "Epoch 6/90\n",
            "375/375 [==============================] - 9s 25ms/step - loss: 0.0783 - accuracy: 0.9754 - f1_m: 0.9759 - precision_m: 0.9789 - recall_m: 0.9729 - val_loss: 0.0536 - val_accuracy: 0.9842 - val_f1_m: 0.9844 - val_precision_m: 0.9863 - val_recall_m: 0.9825\n",
            "Epoch 7/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0719 - accuracy: 0.9777 - f1_m: 0.9779 - precision_m: 0.9803 - recall_m: 0.9755 - val_loss: 0.0503 - val_accuracy: 0.9850 - val_f1_m: 0.9855 - val_precision_m: 0.9875 - val_recall_m: 0.9835\n",
            "Epoch 8/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0674 - accuracy: 0.9787 - f1_m: 0.9791 - precision_m: 0.9813 - recall_m: 0.9769 - val_loss: 0.0436 - val_accuracy: 0.9871 - val_f1_m: 0.9871 - val_precision_m: 0.9889 - val_recall_m: 0.9853\n",
            "Epoch 9/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0613 - accuracy: 0.9806 - f1_m: 0.9809 - precision_m: 0.9829 - recall_m: 0.9789 - val_loss: 0.0411 - val_accuracy: 0.9887 - val_f1_m: 0.9890 - val_precision_m: 0.9905 - val_recall_m: 0.9876\n",
            "Epoch 10/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0583 - accuracy: 0.9814 - f1_m: 0.9814 - precision_m: 0.9832 - recall_m: 0.9795 - val_loss: 0.0412 - val_accuracy: 0.9882 - val_f1_m: 0.9883 - val_precision_m: 0.9893 - val_recall_m: 0.9873\n",
            "Epoch 11/90\n",
            "375/375 [==============================] - 9s 23ms/step - loss: 0.0551 - accuracy: 0.9831 - f1_m: 0.9831 - precision_m: 0.9848 - recall_m: 0.9814 - val_loss: 0.0411 - val_accuracy: 0.9871 - val_f1_m: 0.9873 - val_precision_m: 0.9885 - val_recall_m: 0.9861\n",
            "Epoch 12/90\n",
            "375/375 [==============================] - 9s 23ms/step - loss: 0.0528 - accuracy: 0.9838 - f1_m: 0.9838 - precision_m: 0.9854 - recall_m: 0.9823 - val_loss: 0.0374 - val_accuracy: 0.9887 - val_f1_m: 0.9889 - val_precision_m: 0.9900 - val_recall_m: 0.9878\n",
            "Epoch 13/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0523 - accuracy: 0.9834 - f1_m: 0.9836 - precision_m: 0.9851 - recall_m: 0.9821 - val_loss: 0.0378 - val_accuracy: 0.9890 - val_f1_m: 0.9889 - val_precision_m: 0.9898 - val_recall_m: 0.9879\n",
            "Epoch 14/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0506 - accuracy: 0.9840 - f1_m: 0.9840 - precision_m: 0.9854 - recall_m: 0.9826 - val_loss: 0.0354 - val_accuracy: 0.9894 - val_f1_m: 0.9896 - val_precision_m: 0.9904 - val_recall_m: 0.9888\n",
            "Epoch 15/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0479 - accuracy: 0.9845 - f1_m: 0.9846 - precision_m: 0.9859 - recall_m: 0.9833 - val_loss: 0.0378 - val_accuracy: 0.9901 - val_f1_m: 0.9902 - val_precision_m: 0.9913 - val_recall_m: 0.9892\n",
            "Epoch 16/90\n",
            "375/375 [==============================] - 9s 23ms/step - loss: 0.0448 - accuracy: 0.9855 - f1_m: 0.9857 - precision_m: 0.9872 - recall_m: 0.9843 - val_loss: 0.0351 - val_accuracy: 0.9902 - val_f1_m: 0.9906 - val_precision_m: 0.9914 - val_recall_m: 0.9897\n",
            "Epoch 17/90\n",
            "375/375 [==============================] - 8s 23ms/step - loss: 0.0442 - accuracy: 0.9851 - f1_m: 0.9853 - precision_m: 0.9864 - recall_m: 0.9841 - val_loss: 0.0340 - val_accuracy: 0.9899 - val_f1_m: 0.9902 - val_precision_m: 0.9911 - val_recall_m: 0.9893\n",
            "Epoch 18/90\n",
            "375/375 [==============================] - 9s 23ms/step - loss: 0.0459 - accuracy: 0.9856 - f1_m: 0.9857 - precision_m: 0.9870 - recall_m: 0.9844 - val_loss: 0.0363 - val_accuracy: 0.9894 - val_f1_m: 0.9896 - val_precision_m: 0.9905 - val_recall_m: 0.9888\n",
            "Epoch 19/90\n",
            "375/375 [==============================] - 9s 23ms/step - loss: 0.0433 - accuracy: 0.9865 - f1_m: 0.9866 - precision_m: 0.9877 - recall_m: 0.9855 - val_loss: 0.0358 - val_accuracy: 0.9893 - val_f1_m: 0.9895 - val_precision_m: 0.9902 - val_recall_m: 0.9888\n",
            "Epoch 20/90\n",
            "375/375 [==============================] - 8s 23ms/step - loss: 0.0427 - accuracy: 0.9861 - f1_m: 0.9864 - precision_m: 0.9876 - recall_m: 0.9851 - val_loss: 0.0340 - val_accuracy: 0.9898 - val_f1_m: 0.9899 - val_precision_m: 0.9905 - val_recall_m: 0.9893\n",
            "Epoch 21/90\n",
            "375/375 [==============================] - 9s 23ms/step - loss: 0.0414 - accuracy: 0.9866 - f1_m: 0.9867 - precision_m: 0.9876 - recall_m: 0.9859 - val_loss: 0.0345 - val_accuracy: 0.9897 - val_f1_m: 0.9896 - val_precision_m: 0.9906 - val_recall_m: 0.9887\n",
            "Epoch 22/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0405 - accuracy: 0.9868 - f1_m: 0.9869 - precision_m: 0.9880 - recall_m: 0.9858 - val_loss: 0.0352 - val_accuracy: 0.9896 - val_f1_m: 0.9898 - val_precision_m: 0.9906 - val_recall_m: 0.9890\n",
            "Epoch 23/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0413 - accuracy: 0.9869 - f1_m: 0.9869 - precision_m: 0.9881 - recall_m: 0.9857 - val_loss: 0.0328 - val_accuracy: 0.9898 - val_f1_m: 0.9901 - val_precision_m: 0.9911 - val_recall_m: 0.9892\n",
            "Epoch 24/90\n",
            "375/375 [==============================] - 9s 25ms/step - loss: 0.0390 - accuracy: 0.9875 - f1_m: 0.9877 - precision_m: 0.9887 - recall_m: 0.9868 - val_loss: 0.0327 - val_accuracy: 0.9904 - val_f1_m: 0.9904 - val_precision_m: 0.9910 - val_recall_m: 0.9899\n",
            "Epoch 25/90\n",
            "375/375 [==============================] - 9s 23ms/step - loss: 0.0384 - accuracy: 0.9872 - f1_m: 0.9874 - precision_m: 0.9883 - recall_m: 0.9866 - val_loss: 0.0324 - val_accuracy: 0.9907 - val_f1_m: 0.9908 - val_precision_m: 0.9914 - val_recall_m: 0.9902\n",
            "Epoch 26/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0386 - accuracy: 0.9877 - f1_m: 0.9879 - precision_m: 0.9887 - recall_m: 0.9871 - val_loss: 0.0345 - val_accuracy: 0.9900 - val_f1_m: 0.9901 - val_precision_m: 0.9909 - val_recall_m: 0.9893\n",
            "Epoch 27/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0389 - accuracy: 0.9879 - f1_m: 0.9880 - precision_m: 0.9889 - recall_m: 0.9872 - val_loss: 0.0314 - val_accuracy: 0.9907 - val_f1_m: 0.9906 - val_precision_m: 0.9915 - val_recall_m: 0.9897\n",
            "Epoch 28/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0374 - accuracy: 0.9876 - f1_m: 0.9879 - precision_m: 0.9889 - recall_m: 0.9868 - val_loss: 0.0301 - val_accuracy: 0.9913 - val_f1_m: 0.9912 - val_precision_m: 0.9921 - val_recall_m: 0.9904\n",
            "Epoch 29/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0367 - accuracy: 0.9878 - f1_m: 0.9880 - precision_m: 0.9889 - recall_m: 0.9871 - val_loss: 0.0303 - val_accuracy: 0.9902 - val_f1_m: 0.9906 - val_precision_m: 0.9913 - val_recall_m: 0.9898\n",
            "Epoch 30/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0342 - accuracy: 0.9889 - f1_m: 0.9890 - precision_m: 0.9897 - recall_m: 0.9883 - val_loss: 0.0312 - val_accuracy: 0.9909 - val_f1_m: 0.9907 - val_precision_m: 0.9912 - val_recall_m: 0.9902\n",
            "Epoch 31/90\n",
            "375/375 [==============================] - 8s 20ms/step - loss: 0.0347 - accuracy: 0.9888 - f1_m: 0.9888 - precision_m: 0.9894 - recall_m: 0.9881 - val_loss: 0.0314 - val_accuracy: 0.9903 - val_f1_m: 0.9902 - val_precision_m: 0.9908 - val_recall_m: 0.9897\n",
            "Epoch 32/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0358 - accuracy: 0.9883 - f1_m: 0.9882 - precision_m: 0.9890 - recall_m: 0.9875 - val_loss: 0.0335 - val_accuracy: 0.9905 - val_f1_m: 0.9905 - val_precision_m: 0.9911 - val_recall_m: 0.9899\n",
            "Epoch 33/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0336 - accuracy: 0.9891 - f1_m: 0.9892 - precision_m: 0.9899 - recall_m: 0.9885 - val_loss: 0.0305 - val_accuracy: 0.9905 - val_f1_m: 0.9906 - val_precision_m: 0.9913 - val_recall_m: 0.9898\n",
            "Epoch 34/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0333 - accuracy: 0.9888 - f1_m: 0.9888 - precision_m: 0.9896 - recall_m: 0.9880 - val_loss: 0.0309 - val_accuracy: 0.9907 - val_f1_m: 0.9906 - val_precision_m: 0.9915 - val_recall_m: 0.9897\n",
            "Epoch 35/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0333 - accuracy: 0.9891 - f1_m: 0.9893 - precision_m: 0.9902 - recall_m: 0.9884 - val_loss: 0.0310 - val_accuracy: 0.9909 - val_f1_m: 0.9908 - val_precision_m: 0.9916 - val_recall_m: 0.9900\n",
            "Epoch 36/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0331 - accuracy: 0.9886 - f1_m: 0.9889 - precision_m: 0.9897 - recall_m: 0.9881 - val_loss: 0.0305 - val_accuracy: 0.9909 - val_f1_m: 0.9910 - val_precision_m: 0.9919 - val_recall_m: 0.9901\n",
            "Epoch 37/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0334 - accuracy: 0.9892 - f1_m: 0.9894 - precision_m: 0.9901 - recall_m: 0.9887 - val_loss: 0.0306 - val_accuracy: 0.9911 - val_f1_m: 0.9911 - val_precision_m: 0.9920 - val_recall_m: 0.9902\n",
            "Epoch 38/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0321 - accuracy: 0.9895 - f1_m: 0.9895 - precision_m: 0.9902 - recall_m: 0.9889 - val_loss: 0.0307 - val_accuracy: 0.9910 - val_f1_m: 0.9912 - val_precision_m: 0.9921 - val_recall_m: 0.9904\n",
            "Epoch 39/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0323 - accuracy: 0.9891 - f1_m: 0.9892 - precision_m: 0.9900 - recall_m: 0.9884 - val_loss: 0.0314 - val_accuracy: 0.9908 - val_f1_m: 0.9912 - val_precision_m: 0.9917 - val_recall_m: 0.9907\n",
            "Epoch 40/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0316 - accuracy: 0.9897 - f1_m: 0.9897 - precision_m: 0.9904 - recall_m: 0.9891 - val_loss: 0.0301 - val_accuracy: 0.9905 - val_f1_m: 0.9906 - val_precision_m: 0.9911 - val_recall_m: 0.9902\n",
            "Epoch 41/90\n",
            "375/375 [==============================] - 8s 20ms/step - loss: 0.0322 - accuracy: 0.9896 - f1_m: 0.9898 - precision_m: 0.9904 - recall_m: 0.9891 - val_loss: 0.0315 - val_accuracy: 0.9905 - val_f1_m: 0.9906 - val_precision_m: 0.9912 - val_recall_m: 0.9901\n",
            "Epoch 42/90\n",
            "375/375 [==============================] - 8s 23ms/step - loss: 0.0326 - accuracy: 0.9888 - f1_m: 0.9889 - precision_m: 0.9897 - recall_m: 0.9880 - val_loss: 0.0288 - val_accuracy: 0.9908 - val_f1_m: 0.9909 - val_precision_m: 0.9915 - val_recall_m: 0.9903\n",
            "Epoch 43/90\n",
            "375/375 [==============================] - 9s 23ms/step - loss: 0.0310 - accuracy: 0.9895 - f1_m: 0.9896 - precision_m: 0.9903 - recall_m: 0.9889 - val_loss: 0.0284 - val_accuracy: 0.9920 - val_f1_m: 0.9920 - val_precision_m: 0.9926 - val_recall_m: 0.9915\n",
            "Epoch 44/90\n",
            "375/375 [==============================] - 9s 24ms/step - loss: 0.0307 - accuracy: 0.9898 - f1_m: 0.9900 - precision_m: 0.9906 - recall_m: 0.9894 - val_loss: 0.0302 - val_accuracy: 0.9910 - val_f1_m: 0.9910 - val_precision_m: 0.9916 - val_recall_m: 0.9904\n",
            "Epoch 45/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0318 - accuracy: 0.9897 - f1_m: 0.9898 - precision_m: 0.9904 - recall_m: 0.9892 - val_loss: 0.0291 - val_accuracy: 0.9910 - val_f1_m: 0.9912 - val_precision_m: 0.9920 - val_recall_m: 0.9904\n",
            "Epoch 46/90\n",
            "375/375 [==============================] - 8s 23ms/step - loss: 0.0303 - accuracy: 0.9896 - f1_m: 0.9897 - precision_m: 0.9904 - recall_m: 0.9890 - val_loss: 0.0299 - val_accuracy: 0.9903 - val_f1_m: 0.9905 - val_precision_m: 0.9914 - val_recall_m: 0.9896\n",
            "Epoch 47/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0308 - accuracy: 0.9894 - f1_m: 0.9895 - precision_m: 0.9902 - recall_m: 0.9889 - val_loss: 0.0289 - val_accuracy: 0.9914 - val_f1_m: 0.9916 - val_precision_m: 0.9921 - val_recall_m: 0.9910\n",
            "Epoch 48/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0299 - accuracy: 0.9899 - f1_m: 0.9900 - precision_m: 0.9907 - recall_m: 0.9893 - val_loss: 0.0300 - val_accuracy: 0.9912 - val_f1_m: 0.9914 - val_precision_m: 0.9918 - val_recall_m: 0.9911\n",
            "Epoch 49/90\n",
            "375/375 [==============================] - 9s 25ms/step - loss: 0.0302 - accuracy: 0.9896 - f1_m: 0.9897 - precision_m: 0.9903 - recall_m: 0.9891 - val_loss: 0.0296 - val_accuracy: 0.9912 - val_f1_m: 0.9914 - val_precision_m: 0.9922 - val_recall_m: 0.9907\n",
            "Epoch 50/90\n",
            "375/375 [==============================] - 9s 23ms/step - loss: 0.0275 - accuracy: 0.9908 - f1_m: 0.9906 - precision_m: 0.9911 - recall_m: 0.9901 - val_loss: 0.0284 - val_accuracy: 0.9917 - val_f1_m: 0.9917 - val_precision_m: 0.9922 - val_recall_m: 0.9913\n",
            "Epoch 51/90\n",
            "375/375 [==============================] - 9s 23ms/step - loss: 0.0303 - accuracy: 0.9901 - f1_m: 0.9900 - precision_m: 0.9908 - recall_m: 0.9893 - val_loss: 0.0315 - val_accuracy: 0.9906 - val_f1_m: 0.9907 - val_precision_m: 0.9913 - val_recall_m: 0.9901\n",
            "Epoch 52/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0282 - accuracy: 0.9903 - f1_m: 0.9904 - precision_m: 0.9910 - recall_m: 0.9899 - val_loss: 0.0313 - val_accuracy: 0.9908 - val_f1_m: 0.9909 - val_precision_m: 0.9916 - val_recall_m: 0.9902\n",
            "Epoch 53/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0289 - accuracy: 0.9903 - f1_m: 0.9903 - precision_m: 0.9908 - recall_m: 0.9897 - val_loss: 0.0295 - val_accuracy: 0.9911 - val_f1_m: 0.9911 - val_precision_m: 0.9918 - val_recall_m: 0.9905\n",
            "Epoch 54/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0263 - accuracy: 0.9911 - f1_m: 0.9911 - precision_m: 0.9918 - recall_m: 0.9904 - val_loss: 0.0300 - val_accuracy: 0.9911 - val_f1_m: 0.9909 - val_precision_m: 0.9914 - val_recall_m: 0.9905\n",
            "Epoch 55/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0281 - accuracy: 0.9902 - f1_m: 0.9903 - precision_m: 0.9908 - recall_m: 0.9898 - val_loss: 0.0316 - val_accuracy: 0.9899 - val_f1_m: 0.9901 - val_precision_m: 0.9908 - val_recall_m: 0.9894\n",
            "Epoch 56/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0266 - accuracy: 0.9909 - f1_m: 0.9910 - precision_m: 0.9916 - recall_m: 0.9905 - val_loss: 0.0306 - val_accuracy: 0.9914 - val_f1_m: 0.9916 - val_precision_m: 0.9921 - val_recall_m: 0.9911\n",
            "Epoch 57/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0269 - accuracy: 0.9908 - f1_m: 0.9909 - precision_m: 0.9915 - recall_m: 0.9903 - val_loss: 0.0307 - val_accuracy: 0.9912 - val_f1_m: 0.9912 - val_precision_m: 0.9915 - val_recall_m: 0.9908\n",
            "Epoch 58/90\n",
            "375/375 [==============================] - 9s 23ms/step - loss: 0.0283 - accuracy: 0.9900 - f1_m: 0.9901 - precision_m: 0.9907 - recall_m: 0.9894 - val_loss: 0.0331 - val_accuracy: 0.9903 - val_f1_m: 0.9903 - val_precision_m: 0.9906 - val_recall_m: 0.9899\n",
            "Epoch 59/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0273 - accuracy: 0.9908 - f1_m: 0.9909 - precision_m: 0.9915 - recall_m: 0.9902 - val_loss: 0.0316 - val_accuracy: 0.9899 - val_f1_m: 0.9902 - val_precision_m: 0.9906 - val_recall_m: 0.9897\n",
            "Epoch 60/90\n",
            "375/375 [==============================] - 9s 23ms/step - loss: 0.0262 - accuracy: 0.9907 - f1_m: 0.9908 - precision_m: 0.9914 - recall_m: 0.9902 - val_loss: 0.0314 - val_accuracy: 0.9905 - val_f1_m: 0.9907 - val_precision_m: 0.9911 - val_recall_m: 0.9903\n",
            "Epoch 61/90\n",
            "375/375 [==============================] - 9s 24ms/step - loss: 0.0275 - accuracy: 0.9911 - f1_m: 0.9910 - precision_m: 0.9916 - recall_m: 0.9904 - val_loss: 0.0322 - val_accuracy: 0.9913 - val_f1_m: 0.9913 - val_precision_m: 0.9916 - val_recall_m: 0.9910\n",
            "Epoch 62/90\n",
            "375/375 [==============================] - 9s 25ms/step - loss: 0.0279 - accuracy: 0.9906 - f1_m: 0.9908 - precision_m: 0.9914 - recall_m: 0.9901 - val_loss: 0.0309 - val_accuracy: 0.9904 - val_f1_m: 0.9906 - val_precision_m: 0.9910 - val_recall_m: 0.9902\n",
            "Epoch 63/90\n",
            "375/375 [==============================] - 9s 24ms/step - loss: 0.0275 - accuracy: 0.9909 - f1_m: 0.9909 - precision_m: 0.9915 - recall_m: 0.9904 - val_loss: 0.0293 - val_accuracy: 0.9911 - val_f1_m: 0.9913 - val_precision_m: 0.9917 - val_recall_m: 0.9909\n",
            "Epoch 64/90\n",
            "375/375 [==============================] - 10s 28ms/step - loss: 0.0235 - accuracy: 0.9917 - f1_m: 0.9918 - precision_m: 0.9923 - recall_m: 0.9913 - val_loss: 0.0299 - val_accuracy: 0.9910 - val_f1_m: 0.9912 - val_precision_m: 0.9916 - val_recall_m: 0.9907\n",
            "Epoch 65/90\n",
            "375/375 [==============================] - 9s 24ms/step - loss: 0.0251 - accuracy: 0.9914 - f1_m: 0.9915 - precision_m: 0.9920 - recall_m: 0.9910 - val_loss: 0.0275 - val_accuracy: 0.9920 - val_f1_m: 0.9921 - val_precision_m: 0.9925 - val_recall_m: 0.9917\n",
            "Epoch 66/90\n",
            "375/375 [==============================] - 9s 23ms/step - loss: 0.0261 - accuracy: 0.9915 - f1_m: 0.9915 - precision_m: 0.9921 - recall_m: 0.9909 - val_loss: 0.0277 - val_accuracy: 0.9922 - val_f1_m: 0.9921 - val_precision_m: 0.9925 - val_recall_m: 0.9917\n",
            "Epoch 67/90\n",
            "375/375 [==============================] - 9s 23ms/step - loss: 0.0245 - accuracy: 0.9916 - f1_m: 0.9915 - precision_m: 0.9921 - recall_m: 0.9910 - val_loss: 0.0293 - val_accuracy: 0.9910 - val_f1_m: 0.9910 - val_precision_m: 0.9914 - val_recall_m: 0.9907\n",
            "Epoch 68/90\n",
            "375/375 [==============================] - 9s 23ms/step - loss: 0.0253 - accuracy: 0.9917 - f1_m: 0.9916 - precision_m: 0.9921 - recall_m: 0.9911 - val_loss: 0.0335 - val_accuracy: 0.9908 - val_f1_m: 0.9910 - val_precision_m: 0.9914 - val_recall_m: 0.9906\n",
            "Epoch 69/90\n",
            "375/375 [==============================] - 8s 23ms/step - loss: 0.0248 - accuracy: 0.9916 - f1_m: 0.9916 - precision_m: 0.9923 - recall_m: 0.9910 - val_loss: 0.0317 - val_accuracy: 0.9909 - val_f1_m: 0.9910 - val_precision_m: 0.9915 - val_recall_m: 0.9905\n",
            "Epoch 70/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0256 - accuracy: 0.9911 - f1_m: 0.9911 - precision_m: 0.9915 - recall_m: 0.9907 - val_loss: 0.0327 - val_accuracy: 0.9905 - val_f1_m: 0.9907 - val_precision_m: 0.9911 - val_recall_m: 0.9902\n",
            "Epoch 71/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0256 - accuracy: 0.9912 - f1_m: 0.9912 - precision_m: 0.9917 - recall_m: 0.9908 - val_loss: 0.0292 - val_accuracy: 0.9919 - val_f1_m: 0.9922 - val_precision_m: 0.9925 - val_recall_m: 0.9918\n",
            "Epoch 72/90\n",
            "375/375 [==============================] - 9s 23ms/step - loss: 0.0262 - accuracy: 0.9910 - f1_m: 0.9911 - precision_m: 0.9915 - recall_m: 0.9906 - val_loss: 0.0274 - val_accuracy: 0.9923 - val_f1_m: 0.9923 - val_precision_m: 0.9928 - val_recall_m: 0.9917\n",
            "Epoch 73/90\n",
            "375/375 [==============================] - 9s 23ms/step - loss: 0.0263 - accuracy: 0.9912 - f1_m: 0.9913 - precision_m: 0.9917 - recall_m: 0.9908 - val_loss: 0.0295 - val_accuracy: 0.9916 - val_f1_m: 0.9919 - val_precision_m: 0.9925 - val_recall_m: 0.9914\n",
            "Epoch 74/90\n",
            "375/375 [==============================] - 9s 23ms/step - loss: 0.0256 - accuracy: 0.9912 - f1_m: 0.9911 - precision_m: 0.9916 - recall_m: 0.9906 - val_loss: 0.0316 - val_accuracy: 0.9911 - val_f1_m: 0.9911 - val_precision_m: 0.9915 - val_recall_m: 0.9907\n",
            "Epoch 75/90\n",
            "375/375 [==============================] - 9s 24ms/step - loss: 0.0240 - accuracy: 0.9919 - f1_m: 0.9920 - precision_m: 0.9925 - recall_m: 0.9915 - val_loss: 0.0299 - val_accuracy: 0.9908 - val_f1_m: 0.9910 - val_precision_m: 0.9915 - val_recall_m: 0.9906\n",
            "Epoch 76/90\n",
            "375/375 [==============================] - 9s 24ms/step - loss: 0.0248 - accuracy: 0.9916 - f1_m: 0.9915 - precision_m: 0.9923 - recall_m: 0.9908 - val_loss: 0.0294 - val_accuracy: 0.9919 - val_f1_m: 0.9921 - val_precision_m: 0.9926 - val_recall_m: 0.9916\n",
            "Epoch 77/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0261 - accuracy: 0.9906 - f1_m: 0.9907 - precision_m: 0.9912 - recall_m: 0.9902 - val_loss: 0.0297 - val_accuracy: 0.9915 - val_f1_m: 0.9918 - val_precision_m: 0.9922 - val_recall_m: 0.9914\n",
            "Epoch 78/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0241 - accuracy: 0.9918 - f1_m: 0.9918 - precision_m: 0.9923 - recall_m: 0.9913 - val_loss: 0.0289 - val_accuracy: 0.9917 - val_f1_m: 0.9917 - val_precision_m: 0.9921 - val_recall_m: 0.9912\n",
            "Epoch 79/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0243 - accuracy: 0.9915 - f1_m: 0.9915 - precision_m: 0.9919 - recall_m: 0.9910 - val_loss: 0.0287 - val_accuracy: 0.9913 - val_f1_m: 0.9914 - val_precision_m: 0.9917 - val_recall_m: 0.9912\n",
            "Epoch 80/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0252 - accuracy: 0.9910 - f1_m: 0.9911 - precision_m: 0.9914 - recall_m: 0.9907 - val_loss: 0.0297 - val_accuracy: 0.9912 - val_f1_m: 0.9913 - val_precision_m: 0.9917 - val_recall_m: 0.9910\n",
            "Epoch 81/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0234 - accuracy: 0.9923 - f1_m: 0.9924 - precision_m: 0.9928 - recall_m: 0.9919 - val_loss: 0.0301 - val_accuracy: 0.9916 - val_f1_m: 0.9917 - val_precision_m: 0.9921 - val_recall_m: 0.9912\n",
            "Epoch 82/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0242 - accuracy: 0.9922 - f1_m: 0.9922 - precision_m: 0.9927 - recall_m: 0.9917 - val_loss: 0.0297 - val_accuracy: 0.9914 - val_f1_m: 0.9915 - val_precision_m: 0.9921 - val_recall_m: 0.9910\n",
            "Epoch 83/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0245 - accuracy: 0.9919 - f1_m: 0.9919 - precision_m: 0.9924 - recall_m: 0.9914 - val_loss: 0.0287 - val_accuracy: 0.9922 - val_f1_m: 0.9925 - val_precision_m: 0.9931 - val_recall_m: 0.9920\n",
            "Epoch 84/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0239 - accuracy: 0.9917 - f1_m: 0.9918 - precision_m: 0.9922 - recall_m: 0.9913 - val_loss: 0.0296 - val_accuracy: 0.9916 - val_f1_m: 0.9917 - val_precision_m: 0.9921 - val_recall_m: 0.9913\n",
            "Epoch 85/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0245 - accuracy: 0.9922 - f1_m: 0.9922 - precision_m: 0.9926 - recall_m: 0.9919 - val_loss: 0.0303 - val_accuracy: 0.9915 - val_f1_m: 0.9916 - val_precision_m: 0.9921 - val_recall_m: 0.9911\n",
            "Epoch 86/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0242 - accuracy: 0.9916 - f1_m: 0.9916 - precision_m: 0.9921 - recall_m: 0.9912 - val_loss: 0.0291 - val_accuracy: 0.9918 - val_f1_m: 0.9919 - val_precision_m: 0.9925 - val_recall_m: 0.9913\n",
            "Epoch 87/90\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0239 - accuracy: 0.9918 - f1_m: 0.9918 - precision_m: 0.9923 - recall_m: 0.9914 - val_loss: 0.0289 - val_accuracy: 0.9920 - val_f1_m: 0.9919 - val_precision_m: 0.9923 - val_recall_m: 0.9916\n",
            "Epoch 88/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0243 - accuracy: 0.9917 - f1_m: 0.9917 - precision_m: 0.9921 - recall_m: 0.9912 - val_loss: 0.0290 - val_accuracy: 0.9921 - val_f1_m: 0.9919 - val_precision_m: 0.9925 - val_recall_m: 0.9913\n",
            "Epoch 89/90\n",
            "375/375 [==============================] - 8s 23ms/step - loss: 0.0229 - accuracy: 0.9921 - f1_m: 0.9921 - precision_m: 0.9926 - recall_m: 0.9917 - val_loss: 0.0293 - val_accuracy: 0.9919 - val_f1_m: 0.9922 - val_precision_m: 0.9930 - val_recall_m: 0.9914\n",
            "Epoch 90/90\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0214 - accuracy: 0.9926 - f1_m: 0.9926 - precision_m: 0.9932 - recall_m: 0.9921 - val_loss: 0.0290 - val_accuracy: 0.9917 - val_f1_m: 0.9919 - val_precision_m: 0.9926 - val_recall_m: 0.9912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "xfBbpnE3Fb22",
        "outputId": "da4f3a10-7a86-4555-f844-0855d35b2035"
      },
      "source": [
        "x_plot = list(range(1,len(network_history.history['val_accuracy']) + 1))\n",
        "\n",
        "\n",
        "def plot_history(network_history):\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.plot(x_plot, network_history.history['loss'])\n",
        "    plt.plot(x_plot, network_history.history['val_loss'])\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "\n",
        "    plt.figure()\n",
        "    # plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.plot(x_plot, network_history.history['accuracy'])\n",
        "    plt.plot(x_plot, network_history.history['val_accuracy'])\n",
        "    plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "plot_history(network_history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FduR5wl9PuVQ"
      },
      "source": [
        "Dal grafico si evidenzia: la perdita diminuisce e la precisione molto simile tra training e validation, non si verifica overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAjjSNAEOedf"
      },
      "source": [
        "**VALUTAZIONE** **SUL TRAINING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBoR5cz9QIWt"
      },
      "source": [
        "\n",
        "\n",
        "Performance sul training\n",
        "\n",
        "Abbiamo un’accuratezza alta del 0,99%., anche le metriche hanno valori alti questo significa che è un buon modello.\n",
        "\n",
        "Inoltre sotto ho  riportato il rapporto di classificazione sul traing set.\n",
        "\n",
        "Come si vede la precisione sul training set in alcune categorie è 1; quindi, i falsi positivi sono molto bassi e i veri positivi sono molto alti.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaR9LOOdFhPX",
        "outputId": "e580cc84-dddf-428f-b01a-cb5d1024645d"
      },
      "source": [
        "score = model.evaluate(x_train, y_train, verbose=0)\n",
        "print ('Train loss', score[0])\n",
        "print('Train accuracy', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss 0.011670236475765705\n",
            "Train accuracy 0.9965999722480774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5gAfl3JOedg",
        "outputId": "36432bbc-2814-4074-ec9f-e5e22ae07321"
      },
      "source": [
        "print(\"\\n%s: %.2f%%\" % ( model.metrics_names[1], score[1]*100))\n",
        "print(\"\\n%s: %.2f%%\" % ( model.metrics_names[2], score[2]*100))\n",
        "print(\"\\n%s: %.2f%%\" % ( model.metrics_names[3], score[3]*100))\n",
        "print(\"\\n%s: %.2f%%\" % ( model.metrics_names[4], score[4]*100))\n",
        "print(\"\\n%s: %.2f\" % ( model.metrics_names[0], score[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "accuracy: 99.66%\n",
            "\n",
            "f1_m: 99.66%\n",
            "\n",
            "precision_m: 99.69%\n",
            "\n",
            "recall_m: 99.64%\n",
            "\n",
            "loss: 0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vegriOoIFh6R",
        "outputId": "a3cf7f18-cf06-43b4-e3c6-739e17828202"
      },
      "source": [
        "predicted = np.round(model.predict(x_train))\n",
        "from sklearn.metrics import classification_report\n",
        "targets = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "print(classification_report(y_train,predicted,  target_names=targets))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      5923\n",
            "           1       1.00      1.00      1.00      6742\n",
            "           2       0.99      1.00      1.00      5958\n",
            "           3       1.00      1.00      1.00      6131\n",
            "           4       1.00      1.00      1.00      5842\n",
            "           5       1.00      1.00      1.00      5421\n",
            "           6       1.00      1.00      1.00      5918\n",
            "           7       0.99      1.00      1.00      6265\n",
            "           8       1.00      1.00      1.00      5851\n",
            "           9       1.00      0.99      0.99      5949\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     60000\n",
            "   macro avg       1.00      1.00      1.00     60000\n",
            "weighted avg       1.00      1.00      1.00     60000\n",
            " samples avg       1.00      1.00      1.00     60000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7LHr4y8Oedh"
      },
      "source": [
        "**VALUTAZIONE SUL TEST SET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YcU88I9Qi_7"
      },
      "source": [
        "Questa valutazione è necessaria per capire se dopo l'addestramento il modello è in grado di generalizzare bene con dati non visti. Si ottengono valori alti accuratezza del 0.98% ottime prestazioni e la perdita è bassa. Inoltre sotto ho  riportato il rapporto di classificazione sul testset.\n",
        "La precisione minore è sul numero 8 il motivo può essere che addestratore confonde con il numero 9. In generale valori molto alti, questo indica che \n",
        "sul set di test ci sono falsi positivi molto bassi e veri positivi molto alti.\n",
        "Quindi possiamo concludere che è un buon modello.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1Ot4gxGXq4i",
        "outputId": "74ab000e-b94f-406f-de8e-641d503f4250"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print ('Test loss', score[0])\n",
        "print('Test accuracy', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss 7.347593784332275\n",
            "Test accuracy 0.9889000058174133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq9dBH8FOedi",
        "outputId": "380aec99-6931-4ede-9ee1-4203cf117a85"
      },
      "source": [
        "print(\"\\n%s: %.2f%%\" % ( model.metrics_names[1], score[1]*100))\n",
        "print(\"\\n%s: %.2f%%\" % ( model.metrics_names[2], score[2]*100))\n",
        "print(\"\\n%s: %.2f%%\" % ( model.metrics_names[3], score[3]*100))\n",
        "print(\"\\n%s: %.2f%%\" % ( model.metrics_names[4], score[4]*100))\n",
        "print(\"\\n%s: %.2f\" % ( model.metrics_names[0], score[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "accuracy: 98.89%\n",
            "\n",
            "f1_m: 98.89%\n",
            "\n",
            "precision_m: 98.89%\n",
            "\n",
            "recall_m: 98.89%\n",
            "\n",
            "loss: 7.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMcr0_TWXu06",
        "outputId": "3e3f6f9a-c4bb-4bd3-d1d9-5d82810c2463"
      },
      "source": [
        "predicted = np.round(model.predict(x_test))\n",
        "from sklearn.metrics import classification_report\n",
        "targets = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "print(classification_report(y_test,predicted,  target_names=targets))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       980\n",
            "           1       1.00      0.97      0.99      1135\n",
            "           2       0.98      0.99      0.99      1032\n",
            "           3       0.99      0.99      0.99      1010\n",
            "           4       0.99      0.99      0.99       982\n",
            "           5       0.99      0.99      0.99       892\n",
            "           6       0.99      0.99      0.99       958\n",
            "           7       1.00      0.98      0.99      1028\n",
            "           8       0.96      1.00      0.98       974\n",
            "           9       0.99      0.99      0.99      1009\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            " samples avg       0.99      0.99      0.99     10000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}